# -*- coding: utf-8 -*-
"""submit_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yDIEy0dNsHR2Vp7lTa3Okj0K-qJW6WlP
"""

import numpy as np
from sklearn.svm import LinearSVC
from scipy.linalg import khatri_rao

################################
# Non Editable Region Starting #
################################
def my_fit(X_train, y_train):
################################
#  Non Editable Region Ending  #
################################
    # Map training challenges to 105-dimensional features
    X_feat = my_map(X_train)

    # Train a linear SVM with squared hinge loss
    clf = LinearSVC(
        penalty='l2',
        loss='hinge',
        C=0.1,
        tol=1e-3,
        max_iter=10000,
        dual=True
    )
    clf.fit(X_feat, y_train)

    # Extract weight vector and bias term
    w = clf.coef_.flatten()
    b = float(clf.intercept_[0])
    return w, b

################################
# Non Editable Region Starting #
################################
def my_map(X):
################################
#  Non Editable Region Ending  #
################################
    # 1) Convert bits {0,1} â†’ {+1, -1}
    d = 1 - 2 * X
    n_samples, n_bits = d.shape

    # 2) Compute suffix products x_i = prod_{j=i..7} d_j
    suffix = np.cumprod(d[:, ::-1], axis=1)[:, ::-1]

    # 3) Assemble phi(c) = [x0..x6, d0..d7] dimension 15
    phi = np.hstack([suffix[:, :7], d])  # shape: (n_samples, 15)

    # 4) Compute all pairwise products via Khatri-Rao
    cross_all = khatri_rao(phi.T, phi.T).T  # shape: (n_samples, 15*15=225)
    ti, tj = np.triu_indices(15, k=1)
    idx = ti * 15 + tj  # indices of upper-triangular (i<j)
    feat = cross_all[:, idx]  # shape: (n_samples, 105)

    return feat

################################
# Non Editable Region Starting #
################################
def my_decode(w):
################################
#  Non Editable Region Ending  #
################################
    # Invert a 65-dim arbiter PUF model to delays p, q, r, s (each 64-dim)
    model = np.asarray(w, dtype=float)
    if model.size != 65:
        raise ValueError("Model must be length 65 (64 weights + bias)")

    # Extract weights and bias
    wm = model[:-1]
    b = model[-1]

    # Construct alpha, beta
    beta = np.zeros(64, dtype=float)
    beta[63] = b
    alpha = wm.copy()

    # Solve for p, r with q,s=0
    p = alpha + beta
    r = alpha - beta
    q = np.zeros_like(p)
    s = np.zeros_like(r)

    # Ensure non-negativity by shifting
    t1 = max(0.0, -p.min())
    p += t1; q += t1
    t2 = max(0.0, -r.min())
    r += t2; s += t2

    return p, q, r, s